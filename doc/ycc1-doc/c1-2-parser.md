2 Parser
=========

The parser may be the most important part of the front-end of a
compiler. Common practice is to write a parser by hand, but for
simplicity, here we can use `bison` to generate an efficient yet
powerful LALR parser.

## The `bison` interface

First, let's take a look at bison's C interface. After we write all
the rules in a `.y` file, we can generate a `.c` program by invoking
`bison`, which defines all stuff we need to parse a document. The main
parsing function is `yyparse()`, which do the parsing job. It will
call `yylex` to get token and call `yyerror` to handle unexpected
input. These two functions can be implemented by hand, but more
oftenly, `yylex` is generated by `flex`, as we discussed in the last
chapter. To make `yylex` usable by `bison`, all we need to do is to
let flex program return tokens defined by bison.

This is a simple structure, which has some disadvantages. First, these
auto-generated programs pour a lot names to the global namespace,
which is kind of annoying when we want to design a pretty class
architecture. Second, debugging, testing, error handling, and much
more, is more complex in pure C. Third, after parsing, we want to
generate an AST. The simple but not really flexible structure can make
more difficulties for us. Therefore, I tried to use the pure C++
interface provided by `bison` and `flex` as an experimental feature.

The C++ architecture is a bit more complicated. We have
`ParsingParsingDriver` class handling input, output, diagnostics, AST
manipulation, etc. Two members that do the actual scanning and parsing
job is of class `Lexer` and `Parser`, respectively. These two classes
are generated by `flex` and `bison` with proper parameters. Token
types are encapsulated in `Parser`, as well as position and location
types that are used for error handling. What the parser call to get
next token remains `yylex`. However, we redefine it as
`Lexer::lex()`. In addition, everything generated are placed in
namespace yy, which makes the whole place much cleaner.

## The grammar

After we make this clear, we may take a deeper look at the grammar
rules. The rules are basically the same as design, with a few changes
made to satisfy the LALR parse table generater.

When `bison` encounter a case which it doesn't know whether it should
shift or reduce, it will shift by default, and throw a warning. We can
handle this more gracefully. The most important facility here is
*precedence*. Precedence defines an explicit rule of the shifting
behavior. The rule is simple: when `bison` encounter an operator, it
will take a look at the previous operator at the same level, and
deside whether it should shift in this token. If previous token's
precedence is lower than the current one, or the precedence is the
same but it is right-associative, this token is shifted, and vice
versa. By this rule, we define precedence and associativity for
operators, and define precedence for `if`, parentheses, and
`else`. This help us get rid of all the shift/reduce conflicts.

## Error reporting / recovery

We also want the parser report parsing errors more precisely, and not
to report one at a time. Perfect error handling is rather difficult
using bison, but we can make use of the location and error recovery
features provided to add simple error detection, report, and recovery.

Normally, whenever bison encounter a symbol that should not be here,
it calls `yyerror` to report this, and returns immediately. With
`%locations` option, error report also contains location information,
which enable us to print out the context when reporting error. We can
keep it going in two different ways. We can change the grammar so that
the error is parsed correctly, but we generate a error or warning
manually. We can also use bison's special `error` token, which
represents the error encountered, and is able to skip over some tokens
until it is okay to continue (most commonly until semicolons
occur). If the error is correctly handled, it can continue to the next
grammar unit, as if this unit is parsed correctly with no errors
detected.

Though the first way can be more precise about the error, it can get
the grammar really messy, and even incorrect. This is nice for
warnings, but for handling errors like unmatched parentheses, this way
is much more inconvenient. If we recall our first intention doing so,
we may find that what we care about is error detection and recovery,
and the second way is pretty satisfying for this. So finally I use the
first way for obvious errors like unclosed parentheses in `if` or
`while` statement, and missing type warning in `const` clause, and use
the second way for other syntax errors.

In this solution, we can guarentee that errors are reported (in the
form of "unexpected ..., expect ...", which is kind of naive), and
recovered at next grammar unit. Maybe the biggest disadvantage here is
that it is not so "smart", as `gcc` or `clang` is. It can report
unexpected token when right parenthesis is missing, but can't tell us
which left parenthesis should be matched. However, dealing this not by
grammar but by adding more explicit program logic still make
sense. What's more, this way of detecting errors is more flexible,
because whenever we want a new smart error detection, we don't need to
take great pains to fix the grammar, but only to add a program unit.

Studying some better error handling machanisms, such as that from
`clang` project, is indeed helpful. But before that, we just take this
plain solution and go on.

## Generating AST

During parsing, we also need to store all the information of those
grammar units as a tree structure, which we refer to as AST.

As a tree data structure, we need to define a node (a base class with
several subclasses), store its children's links, and dynamically
generate and destroy those nodes properly. Here we use the convenient
facility provided by C++11: the `shared_ptr`, which provides a simple
yet powerful ref-count garbage collecting pattern. 

All these are just trivial. To visualize the result, we can draw the
tree out using graphviz. Here we implemented a builder pattern and an
abstract factory pattern, with which we can abstract the visualizing
process into two simple methods, and be able to write different
visualizers without changing the main code.

