Understanding clang
===================

Understand how `clang` work might be really helpful for learning
compilers. And we do this by reading the code. However, we may have a
look at how to use it first.

# Usage

>`clang` is a C, C++, and Objective-C compiler which encompasses
>preprocessing, parsing, optimization, code generation, assembly, and
>linking.
>
> *clang MAN page*

Let's use C for example. Though we can compile a C program by just one
line, actually there are at least five steps: preprocessing (turn ".c"
into ".i"), parsing and semantic analysis (generate an AST), code
generation and optimization (turn AST into ".s" or assembly file),
assembling (turn into ".o" or object file), and linking (to generate a
program, or a shared object).

We can use `clang` with different options to run specific phase only.

    -E     Run the preprocessor stage.

    -fsyntax-only
           Run the preprocessor, parser and type checking stages.

    -S     Run the previous stages as well as LLVM generation and
           optimization stages and target-specific code generation,
           producing an assembly file.

    -c     Run all of the above, plus the assembler, generating a
           target ".o" object file.

    no stage selection option
           If no stage selection option is specified, all stages
           above are run, and the linker is run to combine the results
           into an executable or shared library.

# On Code Reading

Before we start to go through the code, maybe we should make some
points clear.

First, this is a fairly huge but organized C++ project. Besides
learning how to write a compiler, we can also learn from it how to
write big programs: how to design class hierarchy, how to perform
tests, how to organize files and directories, how to write docstring
to generate documents automatically, and so forth.

Second, just because the project is too big, we can't read all the
code in a relatively short period of time. Therefore, for important
parts, we can read line by line, and for other parts, the only goal is
to understand what it does, which is described well (in most of the
cases) by its document. So we mainly focus on the structure and the
workflow. Thus, this document is not going to be a complete
documentation for clang, and won't talk about every aspect of it.

Third, instead of reading the code directly, most of the time we'll be
looking at web pages generated by doxygen. Here are a few of the
reasons: Doxygen has a better typesetting, Doxygen provides clear
structure and cross reference for all the code; Doxygen has pages for
code itself, in case we really want to read the code. This indeed
gives us great convenience.

# Doxygen

Though LLVM website provides a full doxygen-generated document,
understanding how doxygen work and generate the document by hand is
still helpful.

TODO: Add description on Doxygen.

To simplify the process of configuring and generating documents,
doxygen even provides a GUI tool called DoxyWizard, which is really
easy to use. I've generated a nice, tidy document using that, with
generating for private members turned on, and code displaying inline.

# The Diagnostics Subsystem

How to generate, format, produce a diagnostic has been discussed a lot
in the "Clang" CFE Internals Manual. Basically, there is a class
called `Diagnostic`, which is used to store warnings and
errors. Diagnostics are stored and later rendered by some
diagnostic client. Locations, levels, and so on, are recorded in
`Diagnostic`s and it is the diagnostic client that decide what to print
out under what level.

# The `Preprocessor` Class and its friends

As described in the Clang CFE Internals Manual, the `Preprocessor` is
really the main interface, so let's just start with it.

The core method of a `Preprocessor` object is `Preprocessor::Lex`,
which returns next `Token` whenever asked. It can get tokens from one
of the two providers: a buffer lexer (`Lexer` class) and a buffered
token stream (`TokenLexer` class). Many novel classes appeared
here. Before we move on, take a look at these basic classes should be
helpful.

## The `Token` class

Tokens read from source as described in the textbook is (surprisingly)
also called `Token`. After the compiler knows more about the
semantics, there would be `AnnotationToken`, which is produced by the
parser, replacing normal tokens in the token stream.

A normal token contain the information about its location, length,
name (if it is an identifier), kind, and flags. Each has a data field
or data structure for storing the information. Among those, the most
used one is `SourceLocation`, which is a rather light data structure,
but contains all you need for a location indicator. Annotation tokens
is not going to be discussed for now.

## The `Lexer` class

`Preprocessor::Lex` will eventually call `Lexer::Lex` to get a
token. The main logic for lexing lies in `Lexer::LexTokenInternal`.

The first thing to notice is that this function contains a lot of
`goto`'s. This is no doubt for efficiency, to reduce the cost calling
a function, or calling functions recursively. But we can see each
label (and code after it) as a function with no parameters and no
returns, and goto a label basically means calling that function, and
do the corresponding job. This is particular useful in this situation,
where, for instance, we want to skip some characters, pretending they
don't exist, and start over. Without goto, we may have to call this
funtion again, which causes trivial, inefficient recursion.

The funtion first creates a local pointer `CurPtr` to point to the
character to be processed, which is assigned the global
`Preprocessor::BufferPtr` at the beginning. Then the funtion gets a
char and decide what to do according to it. Some tool functions are
presented to deal with this pointer, including `getCharAndSize`
(basically returns the current character), `ConsumeChar` (advance the
pointer), and `getAndAdvanceChar` (do the former two operation).

When the character is a letter or an underscore, which means there
comes an identifier, the lexer call `Preprocessor::LexIdentifier` to
lex an identifier and fill in the result token. Same thing happens
with numbers and string literals, where
`Preprocessor::LexNumericalConstant` and
`Preprocessor::LexStringLiteral` are called.

Comments and whitespaces are ignored (when preserving them is not
asked for). Functions like `SkipLineComment`, `SkipBlockComment`,
`SkipWhitespace` are used to advance the pointer and decide where to
stop. They will all update `BufferPtr` so that these parts are
completely skipped by the lexer. Finally the lexer will start over to
get next token (by jumping directly to the beginning of the function).

Preprocessing directives are handled seperately by
`Preprocessor::HandleDirective`, which contains rather straightforward
logic for file importing, macro definitions and conditional clauses.

Interestingly, there is also a class called `TokenLexer`. Instead of
returning on reading, the `TokenLexer` class returns what it has in
its list of tokens that came elsewhere. This is typically used for
returning tokens from a macro definition as it is being expanded, and
other stuff.

# The Parsing Library

[TODO]
